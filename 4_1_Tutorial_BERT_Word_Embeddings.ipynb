{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78HE8FLsKN9Q"
      },
      "source": [
        "The objective of this tutorial is to demonstrate how to obtain contextualized word embeddings from a pre-trained model, Google's BERT. This is a more detailed approach than using the \"feature-extraction\" pipeline, for better understanding of the concepts taught in class.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqa-7WXBAw8q"
      },
      "source": [
        "# 1. Loading Pre-Trained BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCdqJCtQN52l"
      },
      "source": [
        "Install the pytorch interface for BERT by Hugging Face.\n",
        "\n",
        "If you're running this code on Google Colab, you will have to install this library each time you reconnect; the following cell will take care of that for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RfUN_KolV-f",
        "outputId": "64dcd53c-f265-4fc3-e1a0-00338c4f3576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSXImOxMPdNg"
      },
      "source": [
        "Now let's import pytorch, the pretrained BERT model, and a BERT tokenizer.\n",
        "\n",
        "There are several variations of BERT models released, but the one we'll use here is the smaller of the two available sizes (\"base\" and \"large\") and ignoring casing, hence \"uncased.\"\"\n",
        "\n",
        "`transformers` provides a number of classes for applying BERT to different tasks (token classification, text classification, ...). Here, we're going to use the basic `BertModel` which has no specific output task--it's a good choice for using BERT just to extract embeddings. First, load the tokenizer for this model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "4fa30af692b04f94adebe019aee879a5",
            "037be1ebf1584511b105b447872bb541",
            "d3005bbf451f4fc6b497d748297ad38b",
            "35c3adf466a64a3496fc88a3184ae7df",
            "458bfd63528e47abab69611073f37c9c",
            "9ae3640bb8f549cba61d7b32a45e1521",
            "f0dbd4897c0a49d0b5f18efd521874e1",
            "888a46b9db9c4fc58d683ff8f74f005d",
            "f81b570d2af0464c9aaab6b86cccebc5",
            "9db8e0a6a41442e9992e666fdbd24f12",
            "c7ea04ce3dfd4e45a84d46740cf4d34b",
            "782f26c14458425abf55139004ef2bd6",
            "642c37f2e886434a9cc2950e6f4c0b4e",
            "03066ac3edd94256abfdae1fb48f9a18",
            "9027b35575d743dba21df60662323ea8",
            "0ae9233f6fc04c38beb90eb31b165953",
            "e80f459d0a404398b3b3deb805e5e6ff",
            "989503739bf449d09f038d405804d760",
            "868ddf91ceb641cb977d15d229b8d397",
            "d5f74fecc3694e18b295e078272b33c1",
            "774a86106146414ca44b64432b2e67b2",
            "d5f02bc232c149aca8ecdbf570756195",
            "b1289c1c26a64adc8563a870cc12e858",
            "0659a4e4bf7d45e1bf88f2c4f6f2c29f",
            "dce5ddc588f64795827650b1f3ca8105",
            "4768ac822cca4f16ad372e06e3d86c54",
            "cf331fbcf9bf4d74b75e9c6cae49215e",
            "7a1c1c9a619e40679b8d03e50434f33a",
            "090926751a584d28922053bc4ecd982d",
            "56a0cafcc3f744c2839ace09b4def635",
            "4283818777844e5aac66c0de84066943",
            "6f88dcdb304840f284905e9c971726ba",
            "b96e4bc909ce42a69cbc6970d94773af"
          ]
        },
        "id": "lJEnBJ3gHTsQ",
        "outputId": "7ee29433-e4b0-4ddd-8699-fd42cb20d35b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-26 11:08:27.567659: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tlv3VlPnKKHN"
      },
      "source": [
        "# 2. Input Formatting\n",
        "Because BERT is a pretrained model that expects input data in a specific format, we will need:\n",
        "\n",
        "1. A **special token, `[SEP]`,** to mark the end of a sentence, or the separation between two sentences\n",
        "2. A **special token, `[CLS]`,** at the beginning of our text. This token is used for classification tasks, but BERT expects it no matter what your application is.\n",
        "3. Tokens that conform with the fixed vocabulary used in BERT\n",
        "4. The **Token IDs** for the tokens, from BERT's tokenizer\n",
        "5. **Mask IDs** to indicate which elements in the sequence are tokens and which are padding elements\n",
        "6. **Segment IDs** used to distinguish different sentences (for NSP task)\n",
        "7. **Positional Embeddings** used to show token position within the sequence\n",
        "\n",
        "Luckily, the `transformers` interface takes care of all of the above requirements (using the `tokenizer.encode_plus` function).\n",
        "\n",
        "However, since this is intended as an introduction to working with BERT, we're going to perform these steps in a (mostly) manual way for better understanding of what's going on.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gsyrAwYvBfC"
      },
      "source": [
        "## 2.1. Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WafgQPLAWmo"
      },
      "source": [
        "BERT provides its own tokenizer, which we imported above. Let's see how it handles the below sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pg0P9rFxJwwp",
        "outputId": "3154fe0d-10f1-41ba-b822-eac455c69a13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[CLS]', 'my', 'dog', 'is', 'cute', '.', '[SEP]', 'he', 'likes', 'playing', '.', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "sent1 = \"My dog is cute.\"\n",
        "sent2 = \"He likes playing.\"\n",
        "marked_pair = \"[CLS] \" + sent1 + \" [SEP]\" + sent2 + \" [SEP]\"\n",
        "\n",
        "# Tokenize our sentence with the BERT tokenizer.\n",
        "tokenized_pair = tokenizer.tokenize(marked_pair)\n",
        "\n",
        "# Print out the tokens.\n",
        "print (tokenized_pair)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNbVYkuYBON2"
      },
      "source": [
        "BERT tokenizer was created with a WordPiece model. This model greedily creates a fixed-size vocabulary of individual characters, subwords, and words that best fits our language data. Since the vocabulary limit size of our BERT tokenizer model is 30,000, the WordPiece model generated a vocabulary that contains all English characters plus the ~30,000 most common words and subwords found in the English language corpus the model is trained on.\n",
        "\n",
        "Then, for words that are not in the vocabulary, rather than assigning out of vocabulary words to a catch-all token like 'OOV' or 'UNK,'  they are decomposed into subword and character tokens that we can then generate embeddings for.\n",
        "\n",
        "(For more information about WordPiece, see the [original paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/37842.pdf) .)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rYEz7aXA_AQ",
        "outputId": "0789fcf6-6258-4146-c934-57be10c00bf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print(\"playing\" in tokenizer.wordpiece_tokenizer.vocab)\n",
        "print(\"slacking\" in tokenizer.wordpiece_tokenizer.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmqq0eTADQeI",
        "outputId": "98c82cfa-eabd-4de1-8c99-ab0b88e576fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[CLS]', 'my', 'dog', 'is', 'cute', '.', '[SEP]', 'he', 'likes', 'slack', '##ing', '.', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "#let's change the word 'playing' to 'slacking' (not in vocab) in sent2\n",
        "sent2 = \"He likes slacking.\"\n",
        "marked_pair = \"[CLS] \" + sent1 + \" [SEP]\" + sent2 + \" [SEP]\"\n",
        "\n",
        "# Tokenize our sentence with the BERT tokenizer.\n",
        "tokenized_pair = tokenizer.tokenize(marked_pair)\n",
        "\n",
        "# Print out the tokens.\n",
        "print (tokenized_pair)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q51eN4KAkbIJ"
      },
      "source": [
        "Notice how the word \"slackings\" is represented:\n",
        "\n",
        "`['slack', '##ing']`\n",
        "\n",
        "The original word has been split into smaller subwords and characters. The two hash signs preceding some of these subwords are just our tokenizer's way to denote that this subword or character is part of a larger word and preceded by another subword.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp5zXAPBVp82"
      },
      "source": [
        "Here are some examples of the tokens contained in our vocabulary. Tokens beginning with two hashes are subwords or individual characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z1SzuTrqx-7",
        "outputId": "83548051-7362-40d2-cbf1-bf2dffb41d53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30522\n",
            "['canadian', 'earth', '##ity', 'cut', 'degree', 'writing', 'bay', 'christian', 'awarded', 'natural']\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.vocab_size)\n",
        "print(list(tokenizer.vocab.keys())[3010:3020])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoF3LC47VgBb"
      },
      "source": [
        "After breaking the text into tokens, we then have to convert the sentence from a list of strings to a list of vocabulary indices.\n",
        "\n",
        "To illustrate BERT's capability of producing contextualized word embeddings, from here on, we'll use the below example sentence, which contains two instances of the word \"bank\" with different meanings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYjcYJuXoAQx",
        "outputId": "3cd2ab06-4411-4df1-fa8b-23912d362b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS]           101\n",
            "after         2,044\n",
            "stealing     11,065\n",
            "money         2,769\n",
            "from          2,013\n",
            "the           1,996\n",
            "bank          2,924\n",
            "vault        11,632\n",
            ",             1,010\n",
            "the           1,996\n",
            "bank          2,924\n",
            "robber       27,307\n",
            "was           2,001\n",
            "seen          2,464\n",
            "fishing       5,645\n",
            "on            2,006\n",
            "the           1,996\n",
            "mississippi   5,900\n",
            "river         2,314\n",
            "bank          2,924\n",
            ".             1,012\n",
            "[SEP]           102\n"
          ]
        }
      ],
      "source": [
        "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
        "text = \"After stealing money from the bank vault, the bank robber was seen \" \\\n",
        "       \"fishing on the Mississippi river bank.\"\n",
        "\n",
        "# Add the special tokens.\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "# Split the sentence into tokens.\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "# Map the token strings to their vocabulary indeces.\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "# Display the words with their indeces.\n",
        "for tup in zip(tokenized_text, indexed_tokens):\n",
        "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if6C_iCULU60"
      },
      "source": [
        "## 2.2. Segment ID\n",
        "BERT is trained on and expects sentence pairs, using 1s and 0s to distinguish between the two sentences. That is, for each token in \"tokenized_text,\" we must specify which sentence it belongs to: sentence 0 (a series of 0s) or sentence 1 (a series of 1s). For our purposes, single-sentence inputs only require a series of 1s, so we will create a vector of 1s for each token in our input sentence.\n",
        "\n",
        "If you want to process two sentences, assign each word in the first sentence plus the '[SEP]' token a 0, and all tokens of the second sentence a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_jEkVKxJMc0",
        "outputId": "dad470da-c399-4dd8-c3d3-dc2903b1cf9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "# Mark each of the 22 tokens as belonging to sentence \"1\".\n",
        "segments_ids = [1] * len(tokenized_text)\n",
        "\n",
        "print (segments_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Nvaw46mfc8M"
      },
      "source": [
        "\n",
        "Next we need to convert our data to torch tensors and call the BERT model. The BERT PyTorch interface requires that the data be in torch tensors rather than Python lists, so we convert the lists here - this does not change the shape or the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_t4cM6KLc98",
        "outputId": "0f1fc27e-2887-456d-dd74-6a3cc317d8a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 22])\n",
            "torch.Size([1, 22])\n"
          ]
        }
      ],
      "source": [
        "# Convert inputs to PyTorch tensors\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "segments_tensor = torch.tensor([segments_ids])\n",
        "\n",
        "print(tokens_tensor.size())\n",
        "print(segments_tensor.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hlzoi2jWHJyC",
        "outputId": "5785a530-e0d7-4912-8626-43503b985b1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[101, 2044, 11065, 2769, 2013, 1996, 2924, 11632, 1010, 1996, 2924, 27307, 2001, 2464, 5645, 2006, 1996, 5900, 2314, 2924, 1012, 102]\n",
            "{'input_ids': [101, 2044, 11065, 2769, 2013, 1996, 2924, 11632, 1010, 1996, 2924, 27307, 2001, 2464, 5645, 2006, 1996, 5900, 2314, 2924, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ],
      "source": [
        "# Alternatively, function encode_plus() can help us do all the above to prepare the inputs!\n",
        "print(tokenizer.encode(text))\n",
        "print(tokenizer.encode_plus(text))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3iJaX7bmqX2M"
      },
      "outputs": [],
      "source": [
        "# So, with encode_plus(), all the preparation is just one line of code\n",
        "encoding = tokenizer.encode_plus(text, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-nY9LASLr2L"
      },
      "source": [
        "# 3. Extracting Embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl-iCj8wMEd5"
      },
      "source": [
        "## 3.1. Running BERT on our text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCIGe0AXfg4Z"
      },
      "source": [
        "Calling `from_pretrained` will fetch the model from the internet. When we load the `bert-base-uncased`, we see the definition of the model printed in the logging. The model is a deep neural network with 12 layers! Explaining the layers and their functions is outside the scope of this post, and you can skip over this output for now.\n",
        "\n",
        "model.eval() puts our model in evaluation mode as opposed to training mode. In this case, evaluation mode turns off dropout regularization which is used in training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798,
          "referenced_widgets": [
            "a819a2c7627c4c90817f38fe8cdb1b25",
            "a979d8ffa5c04c8da21d182697de7af9",
            "98d2f5e918694f579a860207d673dc9c",
            "2721a168ae884f2baaead93a6f387315",
            "04fd5d88ebc14e9e81835dc78b926566",
            "a3e1eb3e0c034ba5a6553535f90042cf",
            "f51c5511795e48708ca8d1775ac07252",
            "ce33f998e17f4736b6a231ab89fe6693",
            "b52621f1a1e74125b354c71269c92ee8",
            "00bd04fb92a541c1a3c61a0863932a30",
            "a3bc98f8170c4049ba26de6ccc34431c"
          ]
        },
        "id": "Mq2PKplWfbFv",
        "outputId": "78a13e46-a360-49c0-dadf-a38b8b76948d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fe77c16bc8941488b122cbdf4549044",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load pre-trained model (weights). The model returns all hidden-states.\n",
        "\n",
        "model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True )\n",
        "\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation. (no change to the model)\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4Qa5KkkM2Aq"
      },
      "source": [
        "Next, let's evaluate BERT on our example text, and fetch the hidden states of the network!\n",
        "\n",
        "*Side note: `torch.no_grad` tells PyTorch not to construct the compute graph during this forward pass (since we won't be running backprop here)--this just reduces memory consumption and speeds things up a little.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nN0QTZwiMzeq"
      },
      "outputs": [],
      "source": [
        "# Run the text through BERT, and collect all of the hidden states produced\n",
        "# from all 12 layers.\n",
        "with torch.no_grad():\n",
        "\n",
        "    outputs = model(tokens_tensor, segments_tensor)\n",
        "    #outputs = model(**encoding) #if we are getting prepared data from encode_plus()\n",
        "\n",
        "    # Evaluating the model will return a different number of objects based on\n",
        "    # how it's  configured in the `from_pretrained` call earlier. In this case,\n",
        "    # becase we set `output_hidden_states = True`, the third item will be the\n",
        "    # hidden states from all layers. See the documentation for more details:\n",
        "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "    hidden_states = outputs[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeQNEFbUgMSf"
      },
      "source": [
        "## 3.2. Understanding the Output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKTlTS_sfuAe"
      },
      "source": [
        "\n",
        "The full set of hidden states for this model, stored in the object `hidden_states`, has four dimensions, in the following order:\n",
        "\n",
        "1. The layer number (13 layers)\n",
        "2. The batch number (1 sentence)\n",
        "3. The word / token number (22 tokens in our sentence)\n",
        "4. The hidden unit / feature number (768 features)\n",
        "\n",
        "Wait, 13 layers? Because the first element is the input embeddings, the rest is the outputs of each of BERT's 12 layers.\n",
        "\n",
        "That’s 219,648 unique values just to represent our one sentence!\n",
        "\n",
        "The second dimension, the batch size, is used when submitting multiple sentences to the model at once; here, though, we just have one example sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI_uxiW7eRWA",
        "outputId": "52b24543-a755-4abf-aca1-a462ff5de95a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
            "Number of batches: 1\n",
            "Number of tokens: 22\n",
            "Number of hidden units: 768\n"
          ]
        }
      ],
      "source": [
        "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
        "layer_i = 0\n",
        "\n",
        "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
        "batch_i = 0\n",
        "\n",
        "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
        "token_i = 0\n",
        "\n",
        "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Uc_S_hmOWe7"
      },
      "source": [
        "Let's take a quick look at the range of values for a given layer and token.\n",
        "\n",
        "You'll find that the range is fairly similar for all layers and tokens, with the majority of values falling between \\[-2, 2\\], and a small number of values around -8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "u-5aOxJ993Lp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "id": "-UF_OAO-S1sP",
        "outputId": "08979c37-4201-460b-ef57-2352f1453ed1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# For the 7th token 'bank' in our sentence, select its feature values from layer 5.\n",
        "token_i = 6\n",
        "layer_i = 5\n",
        "vec = hidden_states[layer_i][batch_i][token_i]\n",
        "\n",
        "# Plot the values as a histogram to show their distribution.\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.hist(vec, bins=200)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n194RcReDYfw"
      },
      "source": [
        "Grouping the values by layer makes sense for the model, but for our purposes we want it grouped by token.\n",
        "\n",
        "Current dimensions:\n",
        "\n",
        "`[# layers, # batches, # tokens, # features]`\n",
        "\n",
        "Desired dimensions:\n",
        "\n",
        "`[# tokens, # layers, # features]`\n",
        "\n",
        "Luckily, PyTorch includes the `permute` function for easily rearranging the dimensions of a tensor.\n",
        "\n",
        "However, the first dimension is currently a Python list!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CcY_oRwcHlS",
        "outputId": "bd911d91-0b9f-4be6-fa2e-f8897a5edce7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Type of hidden_states:  <class 'tuple'>\n",
            "Tensor shape for each layer:  torch.Size([1, 22, 768])\n"
          ]
        }
      ],
      "source": [
        "# `hidden_states` is a Python list.\n",
        "print('      Type of hidden_states: ', type(hidden_states))\n",
        "\n",
        "# Each layer in the list is a torch tensor.\n",
        "print('Tensor shape for each layer: ', hidden_states[0].size())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yXZjLSke3F0"
      },
      "source": [
        "Let's combine the layers to make this one whole big tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTJV8AFFcLbL",
        "outputId": "d7180779-fafb-4706-c4f0-ccdebbe329e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([13, 1, 22, 768])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Concatenate the tensors for all layers. We use `stack` here to\n",
        "# create a new dimension in the tensor.\n",
        "token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "\n",
        "token_embeddings.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnBv2TUNhzf4"
      },
      "source": [
        "Let's get rid of the \"batches\" dimension since we don't need it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En4JZ41fh6CI",
        "outputId": "9ee06219-b224-4a4f-8b29-90940872daf6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([13, 22, 768])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove dimension 1, the \"batches\".\n",
        "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "\n",
        "token_embeddings.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVzRfvkbe-Yp"
      },
      "source": [
        "Finally, we can switch around the \"layers\" and \"tokens\" dimensions with `permute`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtDVE58cdeYp",
        "outputId": "d0514981-0aa0-4eab-b2fd-8d9d9171085f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([22, 13, 768])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Swap dimensions 0 and 1.\n",
        "token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "token_embeddings.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey5RhOQ7NGtz"
      },
      "source": [
        "## 3.3. Creating word and sentence vectors from hidden states\n",
        "\n",
        "Now, for each token of our input we have 13 separate vectors each of length 768. Which layer or combination of layers provides the best representation of each token? And how to get a single vector representation of the whole sentence?\n",
        "\n",
        "Unfortunately, there's no single easy answer... Let's try a couple reasonable approaches suggested by the original BERT paper.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76TdtFH8NM9q"
      },
      "source": [
        "### Word Vectors\n",
        "\n",
        "To give you some examples, let's create word vectors in two ways.\n",
        "\n",
        "First, let's **concatenate** the last four layers, giving us a single word vector per token. Each vector will have length `4 x 768 = 3,072`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K54QFUOhlj0r",
        "outputId": "1d7a25a6-1176-4069-d8fd-6dddc26a0859"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([22, 13, 768])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token_embeddings.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv42h9jANMRf",
        "outputId": "a9991722-6c1a-460f-dd03-fdc91569272b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape is: 22 x 3072\n"
          ]
        }
      ],
      "source": [
        "# Stores the token vectors, with shape [22 x 3,072]\n",
        "token_vecs_cat4 = []\n",
        "\n",
        "# `token_embeddings` is a [22 x 13 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for token in token_embeddings:\n",
        "\n",
        "    # `token` is a [13 x 768] tensor: 1 embedding + 12 encoders\n",
        "\n",
        "    # Concatenate the vectors (that is, append them together) from the last\n",
        "    # four layers.\n",
        "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
        "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "\n",
        "    # Use `cat_vec` to represent `token`.\n",
        "    token_vecs_cat4.append(cat_vec)\n",
        "\n",
        "print ('Shape is: %d x %d' % (len(token_vecs_cat4), len(token_vecs_cat4[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnWaByfelM-e"
      },
      "source": [
        "As an alternative method, let's try creating the word vectors by **summing** together the last four layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4DKDtFwiF0S",
        "outputId": "ec871202-47fb-4d62-c8e6-88ee0549c0e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape is: 22 x 768\n"
          ]
        }
      ],
      "source": [
        "# Stores the token vectors, with shape [22 x 768]\n",
        "token_vecs_sum4 = []\n",
        "\n",
        "# `token_embeddings` is a [22 x 13 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for token in token_embeddings:\n",
        "\n",
        "    # `token` is a [13 x 768] tensor: 1 embedding + 12 encoders\n",
        "\n",
        "    # Sum the vectors from the last four layers.\n",
        "    sum_vec = torch.sum(token[-4:], dim=0)\n",
        "\n",
        "    # Use `sum_vec` to represent `token`.\n",
        "    token_vecs_sum4.append(sum_vec)\n",
        "\n",
        "print ('Shape is: %d x %d' % (len(token_vecs_sum4), len(token_vecs_sum4[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQaco6jRLkXn"
      },
      "source": [
        "### Sentence Vectors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuul6iQqnXT2"
      },
      "source": [
        "\n",
        "To get a single vector for our entire sentence we have multiple application-dependent strategies, but a simple approach is to average the second to last hiden layer of each token producing a single 768 length vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Zn0n2S-FWZih"
      },
      "outputs": [],
      "source": [
        "# `hidden_states` has shape [13 x 1 x 22 x 768]\n",
        "\n",
        "# `token_vecs` is a tensor with shape [22 x 768]\n",
        "token_vecs = hidden_states[-2][0]\n",
        "\n",
        "# Calculate the average of all 22 token vectors.\n",
        "sentence_embedding = torch.mean(token_vecs, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQv0FL8VWadn",
        "outputId": "54bb2417-6979-4677-dc6c-fd59e6a289e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape before taking average:  torch.Size([22, 768])\n",
            "Our final sentence embedding vector of shape: torch.Size([768])\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape before taking average: \", token_vecs.size())\n",
        "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqYcrAipfE3E"
      },
      "source": [
        "## 3.4. Confirming contextually dependent vectors\n",
        "\n",
        "To confirm that the value of these vectors are in fact contextually dependent, let's look at the different instances of the word \"bank\" in our example sentence:\n",
        "\n",
        "\"After stealing money from the **bank vault**, the **bank robber** was seen fishing on the Mississippi **river bank**.\"\n",
        "\n",
        "Let's find the index of those three instances of the word \"bank\" in the example sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNiRsEh9cmWz",
        "outputId": "10cb9f6c-4774-49d5-e74f-5a97da95c821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 [CLS]\n",
            "1 after\n",
            "2 stealing\n",
            "3 money\n",
            "4 from\n",
            "5 the\n",
            "6 bank\n",
            "7 vault\n",
            "8 ,\n",
            "9 the\n",
            "10 bank\n",
            "11 robber\n",
            "12 was\n",
            "13 seen\n",
            "14 fishing\n",
            "15 on\n",
            "16 the\n",
            "17 mississippi\n",
            "18 river\n",
            "19 bank\n",
            "20 .\n",
            "21 [SEP]\n"
          ]
        }
      ],
      "source": [
        "for i, token_str in enumerate(tokenized_text):\n",
        "  print (i, token_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEhBIA5RlS8-"
      },
      "source": [
        "They are at 6, 10, and 19.\n",
        "\n",
        "For this analysis, we'll use the word vectors that we created by summing the last four layers.\n",
        "\n",
        "We can try printing out their vectors to compare them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9nB252ReRYM7"
      },
      "outputs": [],
      "source": [
        "bank1 = token_vecs_sum4[6]\n",
        "bank2 = token_vecs_sum4[10]\n",
        "bank3 = token_vecs_sum4[19]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBa6vRHknSkv",
        "outputId": "a71452be-b412-4e16-edbf-6a3179020054"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 5 vector values for each instance of \"bank\".\n",
            "\n",
            "'bank' vault    tensor([ 3.3596, -2.9805, -1.5421,  0.7065,  2.0031])\n",
            "'bank' robber   tensor([ 2.7359, -2.5577, -1.3094,  0.6797,  1.6633])\n",
            "river 'bank'    tensor([ 1.5266, -0.8895, -0.5152, -0.9298,  2.8334])\n"
          ]
        }
      ],
      "source": [
        "print('First 5 vector values for each instance of \"bank\".')\n",
        "print('')\n",
        "print(\"\\'bank\\' vault   \", str(bank1[:5]))\n",
        "print(\"\\'bank\\' robber  \", str(bank2[:5]))\n",
        "print(\"river \\'bank\\'   \", str(bank3[:5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca2TCQ_G7SM3"
      },
      "source": [
        "We can see that the values differ, but let's calculate the cosine similarity between the vectors to make a more precise comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYXUwiG0yhBS",
        "outputId": "b7035bb9-175a-43fc-a534-d557b22b1be0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector similarity for  *similar*  meanings:  0.94\n",
            "Vector similarity for *different* meanings:  0.69\n"
          ]
        }
      ],
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Calculate the cosine similarity between the word bank\n",
        "# in \"bank robber\" vs \"river bank\" (different meanings).\n",
        "diff_bank = 1 - cosine(bank2, bank3)\n",
        "\n",
        "# Calculate the cosine similarity between the word bank\n",
        "# in \"bank robber\" vs \"bank vault\" (same meaning).\n",
        "same_bank = 1 - cosine(bank2, bank1)\n",
        "\n",
        "print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
        "print('Vector similarity for *different* meanings:  %.2f' % diff_bank)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7jroXfKspe_"
      },
      "source": [
        "This looks pretty good!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhbZxbKRxMvM"
      },
      "source": [
        "## Cite\n",
        "Chris McCormick and Nick Ryan. (2019, May 14). *BERT Word Embeddings Tutorial*. You can find the original post [here](http://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
        "text1 = \"What's the time now in Singapore?\"\n",
        "text2 = \"What is the weather in Seattle today?\"\n",
        "text3 = \"Apple is looking at buying the U.K. startup for $1 billion.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getavgVector(text):\n",
        "    # Add the special tokens.\n",
        "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "    # Split the sentence into tokens.\n",
        "    tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "    # Map the token strings to their vocabulary indeces.\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "    # Display the words with their indeces.\n",
        "    for tup in zip(tokenized_text, indexed_tokens):\n",
        "        print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n",
        "\n",
        "    segments_ids = [1] * len(tokenized_text)\n",
        "    print (segments_ids)\n",
        "    \n",
        "    # Convert inputs to PyTorch tensors\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensor = torch.tensor([segments_ids])\n",
        "\n",
        "    print(tokens_tensor.size())\n",
        "    print(segments_tensor.size())\n",
        "\n",
        "    # Load pre-trained model (weights). The model returns all hidden-states.\n",
        "\n",
        "    model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                    output_hidden_states = True )\n",
        "\n",
        "    # Put the model in \"evaluation\" mode, meaning feed-forward operation. (no change to the model)\n",
        "    model.eval()\n",
        "    # Run the text through BERT, and collect all of the hidden states produced\n",
        "    # from all 12 layers.\n",
        "    with torch.no_grad():\n",
        "\n",
        "        outputs = model(tokens_tensor, segments_tensor)\n",
        "        #outputs = model(**encoding) #if we are getting prepared data from encode_plus()\n",
        "\n",
        "        # Evaluating the model will return a different number of objects based on\n",
        "        # how it's  configured in the `from_pretrained` call earlier. In this case,\n",
        "        # becase we set `output_hidden_states = True`, the third item will be the\n",
        "        # hidden states from all layers. See the documentation for more details:\n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "        hidden_states = outputs[2]\n",
        "\n",
        "    # Concatenate the tensors for all layers. We use `stack` here to\n",
        "    # create a new dimension in the tensor.\n",
        "    # token_embeddings = torch.stack(hidden_states[1:], dim=0)\n",
        "    # print(token_embeddings.size())\n",
        "    # # Remove dimension 1, the \"batches\".\n",
        "    # token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "    # print(token_embeddings.size())\n",
        "\n",
        "\n",
        "    # `hidden_states` has shape [13 x 1 x 22 x 768]\n",
        "\n",
        "    # `token_vecs` is a tensor with shape [22 x 768]\n",
        "    token_vecs = hidden_states[-2][0]\n",
        "    # token_vecs = token_embeddings[0]\n",
        "\n",
        "    # Calculate the average of all 22 token vectors.\n",
        "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "    return sentence_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS]           101\n",
            "what          2,054\n",
            "'             1,005\n",
            "s             1,055\n",
            "the           1,996\n",
            "time          2,051\n",
            "now           2,085\n",
            "in            1,999\n",
            "singapore     5,264\n",
            "?             1,029\n",
            "[SEP]           102\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 11])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS]           101\n",
            "what          2,054\n",
            "is            2,003\n",
            "the           1,996\n",
            "weather       4,633\n",
            "in            1,999\n",
            "seattle       5,862\n",
            "today         2,651\n",
            "?             1,029\n",
            "[SEP]           102\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS]           101\n",
            "apple         6,207\n",
            "is            2,003\n",
            "looking       2,559\n",
            "at            2,012\n",
            "buying        9,343\n",
            "the           1,996\n",
            "u             1,057\n",
            ".             1,012\n",
            "k             1,047\n",
            ".             1,012\n",
            "startup      22,752\n",
            "for           2,005\n",
            "$             1,002\n",
            "1             1,015\n",
            "billion       4,551\n",
            ".             1,012\n",
            "[SEP]           102\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "torch.Size([1, 18])\n",
            "torch.Size([1, 18])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "sen1vec = getavgVector(text1)\n",
        "sen2vec = getavgVector(text2)\n",
        "sen3vec = getavgVector(text3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8276898264884949\n"
          ]
        }
      ],
      "source": [
        "diff_1_2 = 1 - cosine(sen1vec, sen2vec)\n",
        "print(diff_1_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6033719182014465\n"
          ]
        }
      ],
      "source": [
        "diff_1_3 = 1 - cosine(sen1vec, sen3vec)\n",
        "print(diff_1_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5844821929931641\n"
          ]
        }
      ],
      "source": [
        "diff_2_3 = 1 - cosine(sen2vec, sen3vec)\n",
        "print(diff_2_3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "OhbZxbKRxMvM"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00bd04fb92a541c1a3c61a0863932a30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03066ac3edd94256abfdae1fb48f9a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_868ddf91ceb641cb977d15d229b8d397",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5f74fecc3694e18b295e078272b33c1",
            "value": 28
          }
        },
        "037be1ebf1584511b105b447872bb541": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ae3640bb8f549cba61d7b32a45e1521",
            "placeholder": "​",
            "style": "IPY_MODEL_f0dbd4897c0a49d0b5f18efd521874e1",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "04fd5d88ebc14e9e81835dc78b926566": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0659a4e4bf7d45e1bf88f2c4f6f2c29f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a1c1c9a619e40679b8d03e50434f33a",
            "placeholder": "​",
            "style": "IPY_MODEL_090926751a584d28922053bc4ecd982d",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "090926751a584d28922053bc4ecd982d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ae9233f6fc04c38beb90eb31b165953": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2721a168ae884f2baaead93a6f387315": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00bd04fb92a541c1a3c61a0863932a30",
            "placeholder": "​",
            "style": "IPY_MODEL_a3bc98f8170c4049ba26de6ccc34431c",
            "value": " 440M/440M [00:05&lt;00:00, 115MB/s]"
          }
        },
        "35c3adf466a64a3496fc88a3184ae7df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9db8e0a6a41442e9992e666fdbd24f12",
            "placeholder": "​",
            "style": "IPY_MODEL_c7ea04ce3dfd4e45a84d46740cf4d34b",
            "value": " 232k/232k [00:00&lt;00:00, 4.20MB/s]"
          }
        },
        "4283818777844e5aac66c0de84066943": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "458bfd63528e47abab69611073f37c9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4768ac822cca4f16ad372e06e3d86c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f88dcdb304840f284905e9c971726ba",
            "placeholder": "​",
            "style": "IPY_MODEL_b96e4bc909ce42a69cbc6970d94773af",
            "value": " 570/570 [00:00&lt;00:00, 9.26kB/s]"
          }
        },
        "4fa30af692b04f94adebe019aee879a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_037be1ebf1584511b105b447872bb541",
              "IPY_MODEL_d3005bbf451f4fc6b497d748297ad38b",
              "IPY_MODEL_35c3adf466a64a3496fc88a3184ae7df"
            ],
            "layout": "IPY_MODEL_458bfd63528e47abab69611073f37c9c"
          }
        },
        "56a0cafcc3f744c2839ace09b4def635": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "642c37f2e886434a9cc2950e6f4c0b4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e80f459d0a404398b3b3deb805e5e6ff",
            "placeholder": "​",
            "style": "IPY_MODEL_989503739bf449d09f038d405804d760",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "6f88dcdb304840f284905e9c971726ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "774a86106146414ca44b64432b2e67b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "782f26c14458425abf55139004ef2bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_642c37f2e886434a9cc2950e6f4c0b4e",
              "IPY_MODEL_03066ac3edd94256abfdae1fb48f9a18",
              "IPY_MODEL_9027b35575d743dba21df60662323ea8"
            ],
            "layout": "IPY_MODEL_0ae9233f6fc04c38beb90eb31b165953"
          }
        },
        "7a1c1c9a619e40679b8d03e50434f33a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "868ddf91ceb641cb977d15d229b8d397": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "888a46b9db9c4fc58d683ff8f74f005d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9027b35575d743dba21df60662323ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_774a86106146414ca44b64432b2e67b2",
            "placeholder": "​",
            "style": "IPY_MODEL_d5f02bc232c149aca8ecdbf570756195",
            "value": " 28.0/28.0 [00:00&lt;00:00, 376B/s]"
          }
        },
        "989503739bf449d09f038d405804d760": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98d2f5e918694f579a860207d673dc9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce33f998e17f4736b6a231ab89fe6693",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b52621f1a1e74125b354c71269c92ee8",
            "value": 440449768
          }
        },
        "9ae3640bb8f549cba61d7b32a45e1521": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9db8e0a6a41442e9992e666fdbd24f12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3bc98f8170c4049ba26de6ccc34431c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3e1eb3e0c034ba5a6553535f90042cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a819a2c7627c4c90817f38fe8cdb1b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a979d8ffa5c04c8da21d182697de7af9",
              "IPY_MODEL_98d2f5e918694f579a860207d673dc9c",
              "IPY_MODEL_2721a168ae884f2baaead93a6f387315"
            ],
            "layout": "IPY_MODEL_04fd5d88ebc14e9e81835dc78b926566"
          }
        },
        "a979d8ffa5c04c8da21d182697de7af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3e1eb3e0c034ba5a6553535f90042cf",
            "placeholder": "​",
            "style": "IPY_MODEL_f51c5511795e48708ca8d1775ac07252",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "b1289c1c26a64adc8563a870cc12e858": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0659a4e4bf7d45e1bf88f2c4f6f2c29f",
              "IPY_MODEL_dce5ddc588f64795827650b1f3ca8105",
              "IPY_MODEL_4768ac822cca4f16ad372e06e3d86c54"
            ],
            "layout": "IPY_MODEL_cf331fbcf9bf4d74b75e9c6cae49215e"
          }
        },
        "b52621f1a1e74125b354c71269c92ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b96e4bc909ce42a69cbc6970d94773af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7ea04ce3dfd4e45a84d46740cf4d34b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce33f998e17f4736b6a231ab89fe6693": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf331fbcf9bf4d74b75e9c6cae49215e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3005bbf451f4fc6b497d748297ad38b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_888a46b9db9c4fc58d683ff8f74f005d",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f81b570d2af0464c9aaab6b86cccebc5",
            "value": 231508
          }
        },
        "d5f02bc232c149aca8ecdbf570756195": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5f74fecc3694e18b295e078272b33c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dce5ddc588f64795827650b1f3ca8105": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56a0cafcc3f744c2839ace09b4def635",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4283818777844e5aac66c0de84066943",
            "value": 570
          }
        },
        "e80f459d0a404398b3b3deb805e5e6ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0dbd4897c0a49d0b5f18efd521874e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f51c5511795e48708ca8d1775ac07252": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f81b570d2af0464c9aaab6b86cccebc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
